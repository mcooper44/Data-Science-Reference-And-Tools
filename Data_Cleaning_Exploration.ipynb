{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning | Exploration | Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import matplotlib.ticker as ticker\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the auto dataset\n",
    "X = pd.read_csv('data/auto.csv')\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick check for missing values\n",
    "# if only a handful - you could just drop them\n",
    "print(f'total missing values are: {X.isna().sum().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values - if you want...\n",
    "# alternatively you may interpolate or use some other method for filling things in\n",
    "X.dropna(axis=0, inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(X.price.min(), X.price.max(), 5)\n",
    "g = sns.FacetGrid(X, col=\"make\", hue=\"horsepower-binned\", palette=\"Set2\", col_wrap=4)\n",
    "g.map(plt.hist, 'price', bins=bins, ec=\"k\")\n",
    "\n",
    "g.axes[-1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(X.price.min(), X.price.max(), 5)\n",
    "g = sns.FacetGrid(X, col=\"make\", hue=\"num-of-doors\", palette=\"Set2\", col_wrap=4)\n",
    "g.map(plt.hist, 'price', bins=bins, ec=\"k\")\n",
    "\n",
    "g.axes[-1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(X.price.min(), X.price.max(), 5)\n",
    "g = sns.FacetGrid(X, col=\"make\", hue=\"body-style\", palette=\"Set2\", col_wrap=4)\n",
    "g.map(plt.hist, 'price', bins=bins, ec=\"k\")\n",
    "\n",
    "g.axes[-1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we create a figure using go.Figure and adding trace to it through go.scatter\n",
    "fig = go.Figure(data=go.Scatter(x=X['make'], y=X['price'], mode='markers', marker=dict(color='red')))\n",
    "# Updating layout through `update_layout`. Here we are adding title to the plot and providing title to x and y axis.\n",
    "fig.update_layout(title='Price vs Model', xaxis_title='make', yaxis_title='price')\n",
    "# Display the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bub_data = X.groupby('make')['price'].sum().reset_index()\n",
    "# Create bubble chart here\n",
    "fig = px.scatter(bub_data, x=\"make\", y=\"price\", size=\"price\",\n",
    "                 hover_name=\"make\", title='Make and Price', size_max=60)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(X, x=\"price\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7573f388794f4908a1a58518bee9d992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='make_of_car', options=('alfa-romero', 'audi', 'bmw', 'chevrolet', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.select_car(make_of_car)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "%matplotlib notebook\n",
    "\n",
    "def select_car(make_of_car):\n",
    "    df_filtered= X.loc[X['make'] == make_of_car] \n",
    "    ax = df_filtered[[\"horsepower-binned\", \"price\"]].boxplot( by=\"horsepower-binned\", return_type='axes')\n",
    "    ax[\"price\"].set_title(\"make \" + make_of_car)\n",
    "    print(df_filtered)\n",
    "\n",
    "makes = [m for m in X['make'].unique()]\n",
    "\n",
    "interact(select_car, make_of_car=makes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['due_date'] = pd.to_datetime(df['due_date'])\n",
    "#df['effective_date'] = pd.to_datetime(df['effective_date'])\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Categorical and Numerical Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data set - should categorical columns be encoded first or only after splitting?\n",
    "\n",
    "The general consensus is that it should be encoded after splitting, but for a divergent opinion:\n",
    "https://jamesmccaffrey.wordpress.com/2020/05/27/should-you-normalize-and-encode-data-before-train-test-splitting-or-after-splitting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first it's helpful to see what columns contain what \n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in X.columns if X[cname].nunique() < 3 and \n",
    "                        X[cname].dtype == \"object\"]\n",
    "low_cardinality_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numerical columns\n",
    "numerical_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of categorical variables\n",
    "s = (X.dtypes == 'object')\n",
    "object_cols = list(s[s].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Categorical variables are in columns:\")\n",
    "print(object_cols)\n",
    "print('Numerical variables are in columns:')\n",
    "print(numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print unique values in the categorical columns\n",
    "# NB - if there is a test set - compare the values in the test and training sets to\n",
    "# ensure that the intersection of both sets is complete otherwise the encoding steps\n",
    "# will throw an error\n",
    "for o in object_cols:\n",
    "    print(f'column header \"{o}\" contains these unique values...')\n",
    "    print(X[o].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the categorical columns values is there an inherent ranking present?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ordinal encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remap values with a dictionary manually with replace\n",
    "X.replace({\"num-of-doors\":{'two':2, 'four':4},\n",
    "           \"num-of-cylinders\":{'four':4, 'six':6, 'five':5, 'three':3, 'twelve':12, 'two':2, 'eight':8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html\n",
    "\n",
    "and since it is a blind spot in the documentation - for a clear explanation on how to use categories\n",
    "https://datascience.stackexchange.com/questions/72343/encoding-with-ordinalencoder-how-to-give-levels-as-user-input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# for one column using categories\n",
    "#ordinal_encoder = OrdinalEncoder(categories=[['two','four']])\n",
    "#X_copy = ordinal_encoder.fit_transform(X.loc[:,[\"num-of-doors\"]])\n",
    "\n",
    "# for using multiple - put the labels in order in the lists\n",
    "door_cats = ['two', 'four']\n",
    "cylinder_cats = ['two','three','four', 'five', 'six','eight','twelve']\n",
    "horse_cats = ['Low', 'Medium', 'High']\n",
    "asperation_cats = ['std','turbo']\n",
    "\n",
    "# and then feed them to the encoder class and use the fit_transform method\n",
    "ordinal_encoder = OrdinalEncoder(categories=[door_cats,cylinder_cats,horse_cats,asperation_cats])\n",
    "X[['num-of-doors', 'num-of-cylinders','horsepower-binned','aspiration']] = ordinal_encoder.fit_transform(X[['num-of-doors', \n",
    "                                                                           'num-of-cylinders',\n",
    "                                                                           'horsepower-binned',\n",
    "                                                                            'aspiration']])\n",
    "\n",
    "# or to let the ordinal encoder lable things automatically...\n",
    "#label_X_train[good_label_cols] = ordinal_encoder.fit_transform(X_train[good_label_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[['num-of-doors', 'num-of-cylinders','horsepower-binned','aspiration']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to retrieve the original values\n",
    "ordinal_encoder.inverse_transform(X[['num-of-doors', 'num-of-cylinders','horsepower-binned','aspiration']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### separate X and y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X.price\n",
    "X.drop(['price'], axis=1, inplace=True) \n",
    "# if assigning to another variable remove the inplace\n",
    "# X = X_train.drop(['price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check to make sure nothing is missing\n",
    "y_miss = y.isna().sum().sum()\n",
    "x_miss = X.isna().sum().sum()\n",
    "print(f'X missing values: {y_miss} Y missing values: {x_miss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in numerical_cols:\n",
    "    print('column header', n, 'is numerical and has these stats:')\n",
    "    print('mean', X[n].mean())\n",
    "    print('median', X[n].median())\n",
    "    print('std deviation', X[n].std())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a deeper summary use .describe()\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out all categorical variables from the dataset\n",
    "#drop_X = X.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantifying Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = X.shape[0]\n",
    "num_columns = X.shape[1]\n",
    "print('df is: ',num_rows, 'by', num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many columns in the training data\n",
    "# have missing values?\n",
    "missing_count = (X.isnull().sum())\n",
    "num_cols_with_missing = missing_count[missing_count > 0].count()\n",
    "\n",
    "# Fill in the line below: How many missing entries are contained in \n",
    "# all of the training data?\n",
    "tot_missing = X.isna().sum().sum()\n",
    "print(f'num_rows: {num_rows} num_columns: {num_columns}')\n",
    "print(f'number of columns with missing values: {num_cols_with_missing}')\n",
    "print(f'total number of missing values: {tot_missing}')\n",
    "print()\n",
    "print('columns with missing values + count of missing')\n",
    "print(missing_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names of columns with missing values\n",
    "cols_with_missing = [col for col in X.columns\n",
    "                     if X[col].isnull().any()]\n",
    "cols_with_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pandas.pydata.org/docs/user_guide/missing_data.html#missing-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns in training and validation data with axis=1 \n",
    "reduced_X = X.drop(cols_with_missing, axis=1)\n",
    "reduced_X\n",
    "\n",
    "# alternate\n",
    "# reduced_X_train = X_train.dropna(how='any') #'all' = only drop if all of a row or column is na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows in training and validation data with missing values\n",
    "X.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move to other sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', model)\n",
    "                             ])\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = my_pipeline.predict(X_valid)\n",
    "\n",
    "# Evaluate the model\n",
    "score = mean_absolute_error(y_valid, preds)\n",
    "print('MAE:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain the cross-validation scores with the cross_val_score() function from scikit-learn. We set the number of folds with the cv parameter.\n",
    "\n",
    "The scoring parameter chooses a measure of model quality to report: in this case, we chose negative mean absolute error (MAE). The docs for scikit-learn show a list of options.\n",
    "\n",
    "It is a little surprising that we specify negative MAE. Scikit-learn has a convention where all metrics are defined so a high number is better. Using negatives here allows them to be consistent with that convention, though negative MAE is almost unheard of elsewhere.\n",
    "\n",
    "We typically want a single measure of model quality to compare alternative models. So we take the average across experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Multiply by -1 since sklearn calculates *negative* MAE\n",
    "scores = -1 * cross_val_score(my_pipeline, X, y,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"MAE scores:\\n\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average MAE score (across experiments):\")\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(n_estimators):\n",
    "    \"\"\"Return the average MAE over 3 CV folds of random forest model.\n",
    "    \n",
    "    Keyword argument:\n",
    "    n_estimators -- the number of trees in the forest\n",
    "    \"\"\"\n",
    "    # Replace this body with your own code\n",
    "    a_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', SimpleImputer()),\n",
    "    ('model', RandomForestRegressor(n_estimators=n_estimators, random_state=0))])\n",
    "    a_score = -1 * cross_val_score(a_pipeline, X, y,\n",
    "                              cv=3,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "    return a_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score models with different numbers of esitmators, then plot the scores and look for the elbow\n",
    "results = {}\n",
    "for n in range(50, 450, 50):\n",
    "    results[n] = get_score(n)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(list(results.keys()), list(results.values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
